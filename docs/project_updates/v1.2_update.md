# ğŸ“¢ CORI Update â€“ v1.2
Date:</strong> June 16, 2025

Progressed toward the MVP for <strong>physical-to-symbolic color mapping and virtual sorting</strong>. CORI now scans real-world items (e.g., a red shirt), classifies their dominant color via OpenCV, and logs symbolic sorting decisions. The Gazebo world is configured to support this logic with bins and object placement.

<table>
<tr>
<td>

<h2>âœ… Achievements</h2>

<h3>ğŸ¤– URDF Rebuild & Cleanup</h3>
<ul>
<li>Rebuilt <code>cori.urdf.xacro</code> with full link/joint tree, inertials, and macro-generated fingers</li>
<li>Resolved link duplication, standardized naming, ensured ROS 2 + Gazebo compatibility</li>
</ul>

<h3>ğŸš€ Launch System Refactor</h3>
<ul>
<li>Created clean ROS 2 launch config integrating CORIâ€™s URDF, Gazebo world, and RViz visualization</li>
</ul>

<h3>ğŸŒ Laundry World Complete</h3>
<ul>
<li><code>laundry_world.sdf</code> includes:</li>
<ul>
<li>ğŸ§º Bins: <code>laundry_bin_lights</code>, <code>laundry_bin_darks</code>, <code>laundry_bin_colors</code></li>
<li>ğŸ‘• Clothing props: <code>sock_white</code>, <code>sock_dark</code>, <code>shirt_green</code>, etc.</li>
<li>ğŸª‘ Table layout for object placement</li>
<li>ğŸ§ CORI robot facing table with proper ground contact</li>
</ul>
</ul>

<img src="https://github.com/J-Uptegraph/CORI/blob/main/assets/imgs/CORI_Gazebo_Sim_v1.png" width="1080px"/>

---

<h2>ğŸ¯ MVP Goal</h2>

Enable CORI to:
<ol>
<li>Scan a real-world item via webcam using <code>cori_cv</code></li>
<li>Detect dominant color using OpenCV</li>
<li>Publish label to ROS 2 / Gazebo</li>
<li>Map to a matching virtual cloth object</li>
<li>Simulate sorting into correct bin</li>
</ol>

<strong>System Flow:</strong><br>
<code>Webcam â†’ OpenCV Node â†’ ROS 2 Message â†’ Gazebo Cloth Proxy â†’ Virtual Sorter</code>

---

<h2>ğŸ”§ Next Steps</h2>

<h3>ğŸ‘ï¸ Perception</h3>
<ul>
<li>[ ] Finalize <code>laundry_color_detection.py</code> classification logic (HSV or RGB)</li>
<li>[ ] Publish color labels as ROS 2 messages (e.g., <code>"red"</code>)</li>
</ul>

<h3>ğŸŒ Virtual Bridge</h3>
<ul>
<li>[ ] Develop ROS 2 node to map labels to Gazebo clothing proxies</li>
<li>[ ] Highlight or log selected item in simulation</li>
</ul>

<h3>ğŸ¤– Robotic Sorting</h3>
<ul>
<li>[ ] Prototype pick-and-place logic using CORIâ€™s simulated arm</li>
<li>[ ] Add <code>gazebo_ros2_control</code> plugin for gripper actuation</li>
</ul>

<h3>ğŸ§© System Integration</h3>
<ul>
<li>[ ] Finalize launch stack (vision + sim + message bridge)</li>
<li>[ ] (Optional) Add OpenCV GUI overlay with bounding boxes + category label</li>
</ul>

---

<h3>ğŸ§  Symbolic Detection Live</h3>
<ul>
<li><code>laundry_color_detection.py</code> detects dominant clothing color in real time</li>
<li>Console Output: <code>SORT: RED SCANNED â†’ INTO PILE: COLORS</code></li>
</ul>

<h3>ğŸ§© Modular Architecture</h3>
<ul>
<li>Pipeline is decoupled and modularâ€”ready for ROS 2 integration and testing</li>
<li>Scalable design for multi-object symbolic reasoning</li>
</ul>

</td>
</tr>
</table>
